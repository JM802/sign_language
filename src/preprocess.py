import os
import json
import cv2
import numpy as np
import mediapipe as mp
from tqdm import tqdm
import config  # ç¡®ä¿åŒç›®å½•ä¸‹æœ‰ config.py

# =============================
# åˆå§‹åŒ– MediaPipe Holistic
# =============================
mp_holistic = mp.solutions.holistic
holistic = mp_holistic.Holistic(
    static_image_mode=False,
    model_complexity=1,
    smooth_landmarks=True
)

# =============================
# æå–è§†é¢‘ç‰‡æ®µç‰¹å¾ï¼ˆæŒ‡å®šå¸§åŒºé—´ï¼‰
# =============================
def extract_features(video_path, start_frame, end_frame):
    cap = cv2.VideoCapture(video_path)
    frames_data = []
    current_frame = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        current_frame += 1

        # è·³è¿‡å‰æ®µ
        if current_frame < start_frame:
            continue

        # è¶…è¿‡åæ®µé€€å‡º
        if current_frame > end_frame:
            break

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = holistic.process(image)

        row = []

        # Pose (25 ç‚¹ -> 50ç»´)
        if results.pose_landmarks:
            for i in range(25):
                lm = results.pose_landmarks.landmark[i]
                row.extend([lm.x, lm.y])
        else:
            row.extend([0.0] * 50)

        # Left Hand (21 ç‚¹ -> 42ç»´)
        if results.left_hand_landmarks:
            for lm in results.left_hand_landmarks.landmark:
                row.extend([lm.x, lm.y])
        else:
            row.extend([0.0] * 42)

        # Right Hand (21 ç‚¹ -> 42ç»´)
        if results.right_hand_landmarks:
            for lm in results.right_hand_landmarks.landmark:
                row.extend([lm.x, lm.y])
        else:
            row.extend([0.0] * 42)

        frames_data.append(row)

    cap.release()
    return np.array(frames_data, dtype=np.float32)


# =============================
# è®¡ç®—å…¨å±€å‡å€¼ä¸æ ‡å‡†å·®ï¼ˆä»…è®­ç»ƒé›†ï¼‰
# =============================
def calculate_global_stats(train_list_lines):
    print("ğŸ§® æ­£åœ¨è®¡ç®—å…¨å±€å‡å€¼å’Œæ ‡å‡†å·®...")

    all_data = []

    # è§£æ train_list_linesï¼Œæ¯ä¸€è¡Œæ˜¯ "path,label"
    for line in tqdm(train_list_lines, desc="Loading Train Data"):
        npy_path = line.split(',')[0] # è·å–è·¯å¾„
        
        if os.path.exists(npy_path):
            arr = np.load(npy_path)
            if len(arr) > 0:
                all_data.append(arr)

    if not all_data:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰åŠ è½½åˆ°è®­ç»ƒæ•°æ®ï¼")
        return None, None

    # æ‹¼æ¥å¹¶è®¡ç®—(åšæ­£æ€æ ‡å‡†åŒ–)
    concatenated = np.concatenate(all_data, axis=0)
    mean = np.mean(concatenated, axis=0)
    std = np.std(concatenated, axis=0)
    
    # é˜²æ­¢é™¤ä»¥0
    std = np.where(std == 0, 1.0, std)

    print(f"âœ… ç»Ÿè®¡å®Œæˆã€‚Mean shape: {mean.shape}, Std shape: {std.shape}")
    return mean, std


# =============================
# ä¸»æµç¨‹
# =============================
def process_dataset():
    # æ£€æŸ¥é…ç½®
    if not os.path.exists(config.SPLIT_JSON_PATH):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° JSON æ–‡ä»¶ {config.SPLIT_JSON_PATH}")
        return

    # åˆ›å»ºç›®å½•
    os.makedirs(config.SAVE_NPY_DIR, exist_ok=True)
    os.makedirs(config.MODEL_SAVE_PATH, exist_ok=True)

    print(f"ğŸ“– è¯»å–åˆ’åˆ†æ–‡ä»¶: {config.SPLIT_JSON_PATH}")
    with open(config.SPLIT_JSON_PATH, "r") as f:
        split_data = json.load(f)

    subsets = {"train": [], "val": [], "test": []}

    processed_count = 0
    missing_count = 0

    print("ğŸš€ å¼€å§‹æå–ç‰¹å¾ (æ”¯æŒæ–­ç‚¹ç»­ä¼ )...")

    for video_id, info in tqdm(split_data.items()):
        subset = info["subset"]
        label = info["action"][0]
        start_frame = info["action"][1]
        end_frame = info["action"][2]

        vid_path = os.path.join(config.VIDEO_DIR, f"{video_id}.mp4")
        npy_save_path = os.path.join(config.SAVE_NPY_DIR, f"{video_id}.npy")

        # è§†é¢‘ä¸¢å¤±æ£€æŸ¥
        if not os.path.exists(vid_path):
            missing_count += 1
            continue

        # =============================
        # æ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœå·²æœ‰ npy å°±è·³è¿‡æå–ï¼Œä½†è¦åŠ å…¥åˆ—è¡¨
        # =============================
        if not os.path.exists(npy_save_path):
            try:
                features = extract_features(vid_path, start_frame, end_frame)
                # è¿‡æ»¤ç©ºæ•°æ®æˆ–æçŸ­æ•°æ®
                if len(features) < 1: 
                    continue
                np.save(npy_save_path, features)
            except Exception as e:
                print(f"âš ï¸ å¤„ç†è§†é¢‘ {video_id} å¤±è´¥: {e}")
                continue
        
        # ä¿å­˜å®Œæ•´è·¯å¾„è€Œä¸æ˜¯ IDï¼Œè¿™æ · dataset.py è¯»å–æ—¶ä¸éœ€è¦å†æ‹¼è·¯å¾„ï¼Œå‡å°‘è€¦åˆ
        subsets[subset].append(f"{npy_save_path},{label}")
        processed_count += 1

    # è¾“å‡ºç»Ÿè®¡
    print("\nğŸ“Š å¤„ç†æ‘˜è¦:")
    print(f"   - æˆåŠŸç´¢å¼•: {processed_count}")
    print(f"   - ç¼ºå¤±è§†é¢‘: {missing_count}")
    print(f"   - Trainæ ·æœ¬: {len(subsets['train'])}")
    print(f"   - Valæ ·æœ¬:   {len(subsets['val'])}")
    print(f"   - Testæ ·æœ¬:  {len(subsets['test'])}")

    # ä¿å­˜ map æ–‡ä»¶ (è¿™äº›æ–‡ä»¶ä¼šè¢« Dataset ç±»ç›´æ¥è¯»å–)
    for subset_name, items in subsets.items():
        map_file = os.path.join(config.DATA_ROOT, f"{subset_name}_map_300.txt")
        with open(map_file, "w") as f:
            f.write("\n".join(items))
        print(f"ğŸ’¾ ä¿å­˜ç´¢å¼•æ–‡ä»¶: {map_file}")

    # è®¡ç®—ç»Ÿè®¡é‡ (åªç”¨è®­ç»ƒé›†)
    if len(subsets["train"]) > 0:
        mean, std = calculate_global_stats(subsets["train"])

        if mean is not None:
            np.save(os.path.join(config.DATA_ROOT, "global_mean_300.npy"), mean)
            np.save(os.path.join(config.DATA_ROOT, "global_std_300.npy"), std)
            print("ğŸ’¾ ä¿å­˜å…¨å±€ç»Ÿè®¡é‡ (global_mean_300.npy / global_std_300.npy)")
    else:
        print("âš ï¸ è­¦å‘Šï¼šè®­ç»ƒé›†ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—ç»Ÿè®¡é‡ï¼")

if __name__ == "__main__":
    process_dataset()